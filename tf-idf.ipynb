{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cara 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\"I love this movie\",\n",
    "          \"This movie is terrible\",\n",
    "          \"The plot is confusing\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bow_encoded = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from nltk.tokenize import word_tokenize\n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def create_wordBank(documents):\n",
    "    result = pd.DataFrame()\n",
    "    document_tokens = [doc.split() for doc in documents]\n",
    "    unique_words = [word for document in document_tokens for word in document]\n",
    "    result['word'] = unique_words\n",
    "    result = result['word'].drop_duplicates()\n",
    "    return result\n",
    "\n",
    "def idf(doc, wordBank):\n",
    " #hitung jumlah doc\n",
    " N = doc.count()\n",
    " #buat dataframe dengan header word dan idf\n",
    " result = pd.DataFrame(columns=['word', 'idf'])\n",
    " #untuk setiap kata pada wordBank lakukan.....\n",
    " for word in wordBank:\n",
    "  #hitung jumlah doc yang mengandung kata word['words']\n",
    "  dft = np.sum(doc.str.contains(word))\n",
    "  #hitung inverse document frequency smooth\n",
    "  idft = log(N / (dft + 1), 10)\n",
    "  #tambahkan idf untuk setiap kata pada data frame\n",
    "  result = pd.concat([result, pd.DataFrame({'word':[word],'idf':[idft]})], ignore_index=True)\n",
    " #return variable result\n",
    " return result\n",
    "\n",
    "def tf(doc, wordBank):\n",
    "  #split kata berdasarkan spasi\n",
    "  wordList = doc.str.split(' ')\n",
    "  #hitung jumlah kata pada setiap doc\n",
    "  # maxFt = [len(s) for s in wordList]\n",
    "  #buat DataFrame kosong untuk menyimpan hasil perhitungan Tf\n",
    "  result = pd.DataFrame()\n",
    "  #untuk setiap word dalam wordbank lakukan ....\n",
    "  for word in wordBank:\n",
    "    #hitung frekuensi kata untuk setiap doc\n",
    "    ft = np.add([s.count(word) for s in wordList], 0)\n",
    "    #tf log normalization\n",
    "    ftd = 1 + np.log10(ft)\n",
    "    #tambahkan hasil perhitungan tf kedalam DataFrame\n",
    "    result = pd.concat([result, pd.Series(ftd)],ignore_index=True)\n",
    "  #replace -inf with zero\n",
    "  result = result.replace(-np.inf, 0)\n",
    "  #return variable result\n",
    "  return result\n",
    "\n",
    "def tfIdf(tf, idf):\n",
    " #buat DataFrame kosong untuk menyimpan hasil perhitungan Tf-Idf\n",
    " result = pd.DataFrame()\n",
    " #untuk setiap tf\n",
    " for i in tf:\n",
    "  #tf idf untuk document term weighting tf * idf\n",
    "  tfIdf = tf[i] * idf['idf']\n",
    "  #tambahkan hasil perhitungan tf idf kedalam DataFrame\n",
    "  result = pd.concat([result, pd.Series(tfIdf)], ignore_index=True)\n",
    " #return variable result\n",
    " return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word    [aku]\n",
       "idf       [2]\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.Series({'word': ['aku'],'idf': [2]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I love this movie\",\n",
    "          \"This movie is terrible\",\n",
    "          \"The plot is confusing\"]\n",
    "corpus = pd.DataFrame(corpus)\n",
    "\n",
    "# print(corpus.apply(word_tokenize_wrapper))\n",
    "# resultIDF = idf(corpus, create_wordBank(corpus))\n",
    "# #hitung nilai TF\n",
    "\n",
    "len = corpus.index\n",
    "\n",
    "jumlah = len+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_excel('dataset\\SentimentIbu_kota_pindah_new.xlsx')\n",
    "data1 = data1['text']\n",
    "data1 = data1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(teks):\n",
    "    return ''.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+\\/\\/\\S+)\",\"\",teks))\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "#use function\n",
    "clean = []\n",
    "for i in data1:\n",
    "    clean.append(clean_tweet(i))\n",
    "\n",
    "data1 = pd.DataFrame(clean, columns=['teks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     maksudnya secara gak langsung mau bikin pembe...\n",
       "1    ozil saya turut mendukung proses pemindahan ib...\n",
       "2    kolaborasi menjadi salah satu kunci bagi pemer...\n",
       "3    sch guys aku keterima di ilkom unpad  trivia s...\n",
       "4     ayo kawal proses pemindahan ibukota ibukotane...\n",
       "5     ayo kawal proses pemindahan ibukota ibukotane...\n",
       "6    pemindahan ibukota negara dapat dimaknai lebih...\n",
       "7     trump menangguhkan pemindahan ibukota israel ...\n",
       "8    pemindahan ibu kota mataram kuno oleh mpu sind...\n",
       "9     um pemindahan ibukota kan tidak memindahkan m...\n",
       "Name: teks, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = data1['teks'].str.lower()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      maksudnya\n",
       "1         secara\n",
       "2            gak\n",
       "3       langsung\n",
       "4            mau\n",
       "         ...    \n",
       "188      problem\n",
       "189          its\n",
       "190      running\n",
       "191         away\n",
       "192         from\n",
       "Name: word, Length: 145, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordBank = create_wordBank(data1)\n",
    "wordBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alam\\AppData\\Local\\Temp\\ipykernel_888\\1558316671.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, pd.DataFrame({'word':[word],'idf':[idft]})], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maksudnya</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>secara</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gak</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>langsung</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mau</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>problem</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>its</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>running</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>away</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>from</td>\n",
       "      <td>0.69897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      idf\n",
       "0    maksudnya  0.69897\n",
       "1       secara  0.69897\n",
       "2          gak  0.69897\n",
       "3     langsung  0.69897\n",
       "4          mau  0.69897\n",
       "..         ...      ...\n",
       "140    problem  0.69897\n",
       "141        its  0.69897\n",
       "142    running  0.69897\n",
       "143       away  0.69897\n",
       "144       from  0.69897\n",
       "\n",
       "[145 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultIDF = idf(data1, wordBank)\n",
    "\n",
    "resultIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alam\\AppData\\Local\\Temp\\ipykernel_888\\1974542271.py:44: RuntimeWarning: divide by zero encountered in log10\n",
      "  ftd = 1 + np.log10(ft)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1450 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     1.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "...   ...\n",
       "1445  0.0\n",
       "1446  0.0\n",
       "1447  0.0\n",
       "1448  0.0\n",
       "1449  1.0\n",
       "\n",
       "[1450 rows x 1 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultTF = tf(data1, wordBank)\n",
    "resultTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cara2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['data science is one of the most important fields of science',\n",
    "          'this is one of the best data science courses',\n",
    "          'data scientists analyze data']\n",
    "\n",
    "corp = pd.DataFrame(corpus, columns=['teks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data science is one of the most important fields of science',\n",
       "       'this is one of the best data science courses',\n",
       "       'data scientists analyze data'], dtype='<U59')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks = np.array(corp['teks'])\n",
    "teks = teks.astype(str)\n",
    "teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghitung kata unik yang ada di dalam corpus\n",
    "def uniq_word(corpus):\n",
    "    words_set = set()\n",
    "    for doc in  corpus:\n",
    "        doc = doc.lower()\n",
    "        words = doc.split(' ')\n",
    "        words_set = words_set.union(set(words))\n",
    "    return words_set\n",
    "\n",
    "def compute_tf(words_set, corpus,colom):\n",
    "    n_docs = len(corpus)         #Â·Number of documents in the corpus\n",
    "    n_words_set = len(words_set) #Â·Number of unique words in the\n",
    "    df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=colom)\n",
    "\n",
    "    # Compute Term Frequency (TF)\n",
    "    for i in range(n_docs):\n",
    "        words = corpus[i].split(' ') # memcah semua kata(tokenisasi) yang ada dalam document\n",
    "        # each loop untuk menghitung bobot tf semua kata yang ada dalam doc \n",
    "        for w in words_set:\n",
    "            # menghitung dengan (jumlah kata(t) muncul dalam sebuah dokumen / jumlah seluruh kata yang ada dalam dokumen)\n",
    "            df_tf[w][i] = df_tf[w][i] + (corpus[i].count(w) / len(words))\n",
    "    return df_tf\n",
    "\n",
    "def compute_idf(words_set,n_docs,corpus):\n",
    "    idf = {}\n",
    "    print('the idf :')\n",
    "    for w in words_set:\n",
    "        k = 0    # number of documents in the corpus that contain this word\n",
    "     \n",
    "        # looping untuk menghitung jumlah dokumen yang mengandung kata(T)\n",
    "        for i in range(n_docs):\n",
    "            if w in corpus[i].split():\n",
    "                k += 1\n",
    "\n",
    "        # menghitung idf dengan cara log(jumlah sentimen(doc) dalam corpus/jumlah sentiment(doc) yang menggandung kata unik itu)\n",
    "        # # kalau menggunakan sklearn formulanya agak sedikti berbeda dimana dia menggunakan log(1+ jumlah sentimen(doc) dalam corpus/ 1+jumlah sentiment(doc) yang menggandung kata unik itu)+1  \n",
    "        idf[w] =  math.log(n_docs / k)\n",
    "        print(f'{w:>15}: {idf[w]:>10}' )\n",
    "    return idf\n",
    "\n",
    "def tf_idf_manual(corpus):\n",
    "    corpus = np.array(corpus)\n",
    "    corpus = corpus.astype(str)\n",
    "    \n",
    "    # jumlah semua kata unik yang ada dalam corpus\n",
    "    words_set = uniq_word(corpus)\n",
    "\n",
    "    # make word_set as array (for making a table)\n",
    "    colom = []\n",
    "    for i in words_set:\n",
    "        colom.append(i)\n",
    "\n",
    "    n_docs = len(corpus)         #Â·Number of documents in the corpus\n",
    "    n_words_set = len(words_set) #Â·Number of unique words in the\n",
    "\n",
    "    df_tf = compute_tf(words_set,corpus,colom)\n",
    "    print('the df_tf',df_tf)\n",
    "    df_tf_idf = df_tf.copy()\n",
    "\n",
    "    idf = compute_idf(words_set,n_docs,corpus)\n",
    "\n",
    "    for w in words_set:\n",
    "        for i in range(n_docs):\n",
    "            df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "         \n",
    "    return df_tf_idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the df_tf        most  important   courses        is    fields        of   science  \\\n",
      "0  0.090909   0.090909  0.000000  0.090909  0.090909  0.181818  0.181818   \n",
      "1  0.000000   0.000000  0.111111  0.222222  0.000000  0.111111  0.111111   \n",
      "2  0.000000   0.000000  0.000000  0.250000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       this       the      best      data  scientists  analyze       one  \n",
      "0  0.000000  0.090909  0.000000  0.090909        0.00     0.00  0.090909  \n",
      "1  0.111111  0.111111  0.111111  0.111111        0.00     0.00  0.111111  \n",
      "2  0.000000  0.000000  0.000000  0.500000        0.25     0.25  0.000000  \n",
      "the idf :\n",
      "           most: 1.0986122886681098\n",
      "      important: 1.0986122886681098\n",
      "        courses: 1.0986122886681098\n",
      "             is: 0.4054651081081644\n",
      "         fields: 1.0986122886681098\n",
      "             of: 0.4054651081081644\n",
      "        science: 0.4054651081081644\n",
      "           this: 1.0986122886681098\n",
      "            the: 0.4054651081081644\n",
      "           best: 1.0986122886681098\n",
      "           data:        0.0\n",
      "     scientists: 1.0986122886681098\n",
      "        analyze: 1.0986122886681098\n",
      "            one: 0.4054651081081644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most</th>\n",
       "      <th>important</th>\n",
       "      <th>courses</th>\n",
       "      <th>is</th>\n",
       "      <th>fields</th>\n",
       "      <th>of</th>\n",
       "      <th>science</th>\n",
       "      <th>this</th>\n",
       "      <th>the</th>\n",
       "      <th>best</th>\n",
       "      <th>data</th>\n",
       "      <th>scientists</th>\n",
       "      <th>analyze</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.073721</td>\n",
       "      <td>0.073721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.090103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       most  important   courses        is    fields        of   science  \\\n",
       "0  0.099874   0.099874  0.000000  0.036860  0.099874  0.073721  0.073721   \n",
       "1  0.000000   0.000000  0.122068  0.090103  0.000000  0.045052  0.045052   \n",
       "2  0.000000   0.000000  0.000000  0.101366  0.000000  0.000000  0.000000   \n",
       "\n",
       "       this       the      best  data  scientists   analyze       one  \n",
       "0  0.000000  0.036860  0.000000   0.0    0.000000  0.000000  0.036860  \n",
       "1  0.122068  0.045052  0.122068   0.0    0.000000  0.000000  0.045052  \n",
       "2  0.000000  0.000000  0.000000   0.0    0.274653  0.274653  0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual = tf_idf_manual(corp['teks'])\n",
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(manual)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the corpus: 14\n",
      "The words in the corpus: \n",
      " {'data', 'science', 'is', 'the', 'scientists', 'best', 'courses', 'important', 'this', 'one', 'analyze', 'of', 'most', 'fields'}\n"
     ]
    }
   ],
   "source": [
    "words_set = set()\n",
    " \n",
    "for doc in  teks:\n",
    "    words = doc.split(' ')\n",
    "    words_set = words_set.union(set(words))\n",
    "\n",
    "\n",
    "     \n",
    "print('Number of unique words in the corpus:',len(words_set))\n",
    "print('The words in the corpus: \\n', np.array(words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "colom = []\n",
    "for i in words_set:\n",
    "    colom.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "{'data', 'science', 'is', 'the', 'scientists', 'best', 'courses', 'important', 'this', 'one', 'analyze', 'of', 'most', 'fields'}\n"
     ]
    }
   ],
   "source": [
    "n_docs = len(teks)         #Â·Number of documents in the corpus\n",
    "n_words_set = len(words_set) #Â·Number of unique words in the\n",
    "data_dum = np.zeros((n_docs, n_words_set))\n",
    "\n",
    "print(data_dum)\n",
    "print(words_set)\n",
    "\n",
    "df_tf = pd.DataFrame(np.zeros((n_docs, n_words_set)), columns=colom)\n",
    "\n",
    "# Compute Term Frequency (TF)\n",
    "for i in range(n_docs):\n",
    "    words = teks[i].split(' ') # Words in the document\n",
    "    for w in words:\n",
    "        # menghitung dengan (jumlah kata(t) muncul dalam sebuah dokumen / jumlah seluruh kata yang ada dalam dokumen)\n",
    "        df_tf[w][i] = df_tf[w][i] + (teks[i].count(w) / len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>science</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>scientists</th>\n",
       "      <th>best</th>\n",
       "      <th>courses</th>\n",
       "      <th>important</th>\n",
       "      <th>this</th>\n",
       "      <th>one</th>\n",
       "      <th>analyze</th>\n",
       "      <th>of</th>\n",
       "      <th>most</th>\n",
       "      <th>fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data   science        is       the  scientists      best   courses  \\\n",
       "0  0.090909  0.363636  0.090909  0.090909        0.00  0.000000  0.000000   \n",
       "1  0.111111  0.111111  0.222222  0.111111        0.00  0.111111  0.111111   \n",
       "2  1.000000  0.000000  0.000000  0.000000        0.25  0.000000  0.000000   \n",
       "\n",
       "   important      this       one  analyze        of      most    fields  \n",
       "0   0.090909  0.000000  0.090909     0.00  0.363636  0.090909  0.090909  \n",
       "1   0.000000  0.111111  0.111111     0.00  0.111111  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000     0.25  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF of: \n",
      "           data:        0.0\n",
      "        science: 0.4054651081081644\n",
      "             is: 0.4054651081081644\n",
      "            the: 0.4054651081081644\n",
      "     scientists: 1.0986122886681098\n",
      "           best: 1.0986122886681098\n",
      "        courses: 1.0986122886681098\n",
      "      important: 1.0986122886681098\n",
      "           this: 1.0986122886681098\n",
      "            one: 0.4054651081081644\n",
      "        analyze: 1.0986122886681098\n",
      "             of: 0.4054651081081644\n",
      "           most: 1.0986122886681098\n",
      "         fields: 1.0986122886681098\n"
     ]
    }
   ],
   "source": [
    "print(\"IDF of: \")\n",
    " \n",
    "idf = {}\n",
    " \n",
    "for w in words_set:\n",
    "    k = 0    # number of documents in the corpus that contain this word\n",
    "     \n",
    "    # looping untuk menghitung jumlah dokumen yang mengandung kata(T)\n",
    "    for i in range(n_docs):\n",
    "        if w in teks[i].split():\n",
    "            k += 1\n",
    "\n",
    "    # menghitung idf dengan cara log(jumlah sentimen(doc) dalam corpus/jumlah sentiment(doc) yang menggandung kata unik itu)\n",
    "    # # kalau menggunakan sklearn formulanya agak sedikti berbeda dimana dia menggunakan log(1+ jumlah sentimen(doc) dalam corpus/ 1+jumlah sentiment(doc) yang menggandung kata unik itu)+1  \n",
    "    idf[w] =  math.log(n_docs / k)\n",
    "     \n",
    "    print(f'{w:>15}: {idf[w]:>10}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>science</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>scientists</th>\n",
       "      <th>best</th>\n",
       "      <th>courses</th>\n",
       "      <th>important</th>\n",
       "      <th>this</th>\n",
       "      <th>one</th>\n",
       "      <th>analyze</th>\n",
       "      <th>of</th>\n",
       "      <th>most</th>\n",
       "      <th>fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147442</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147442</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.090103</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data   science        is       the  scientists      best   courses  \\\n",
       "0   0.0  0.147442  0.036860  0.036860    0.000000  0.000000  0.000000   \n",
       "1   0.0  0.045052  0.090103  0.045052    0.000000  0.122068  0.122068   \n",
       "2   0.0  0.000000  0.000000  0.000000    0.274653  0.000000  0.000000   \n",
       "\n",
       "   important      this       one   analyze        of      most    fields  \n",
       "0   0.099874  0.000000  0.036860  0.000000  0.147442  0.099874  0.099874  \n",
       "1   0.000000  0.122068  0.045052  0.000000  0.045052  0.000000  0.000000  \n",
       "2   0.000000  0.000000  0.000000  0.274653  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf = df_tf.copy()\n",
    " \n",
    "for w in words_set:\n",
    "    for i in range(n_docs):\n",
    "        df_tf_idf[w][i] = df_tf[w][i] * idf[w]\n",
    "         \n",
    "df_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_tf_idf = np.array(df_tf_idf)\n",
    "array_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.18952581, 0.32089509,\n",
       "        0.32089509, 0.24404899, 0.32089509, 0.48809797, 0.24404899,\n",
       "        0.48809797, 0.        , 0.24404899, 0.        ],\n",
       "       [0.        , 0.40029393, 0.40029393, 0.23642005, 0.        ,\n",
       "        0.        , 0.30443385, 0.        , 0.30443385, 0.30443385,\n",
       "        0.30443385, 0.        , 0.30443385, 0.40029393],\n",
       "       [0.54270061, 0.        , 0.        , 0.64105545, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54270061, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tr_idf_model  = TfidfVectorizer()\n",
    "tf_idf_vector = tr_idf_model.fit_transform(corpus)\n",
    "\n",
    "tf_idf_array = tf_idf_vector.toarray()\n",
    " \n",
    "tf_idf_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyze</th>\n",
       "      <th>best</th>\n",
       "      <th>courses</th>\n",
       "      <th>data</th>\n",
       "      <th>fields</th>\n",
       "      <th>important</th>\n",
       "      <th>is</th>\n",
       "      <th>most</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>science</th>\n",
       "      <th>scientists</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189526</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244049</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.236420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.400294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analyze      best   courses      data    fields  important        is  \\\n",
       "0  0.000000  0.000000  0.000000  0.189526  0.320895   0.320895  0.244049   \n",
       "1  0.000000  0.400294  0.400294  0.236420  0.000000   0.000000  0.304434   \n",
       "2  0.542701  0.000000  0.000000  0.641055  0.000000   0.000000  0.000000   \n",
       "\n",
       "       most        of       one   science  scientists       the      this  \n",
       "0  0.320895  0.488098  0.244049  0.488098    0.000000  0.244049  0.000000  \n",
       "1  0.000000  0.304434  0.304434  0.304434    0.000000  0.304434  0.400294  \n",
       "2  0.000000  0.000000  0.000000  0.000000    0.542701  0.000000  0.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_set = tr_idf_model.get_feature_names_out()\n",
    "\n",
    "tes = pd.DataFrame(tf_idf_array, columns=words_set)\n",
    "\n",
    "tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Contoh array\n",
    "arr = np.array([0, 1, 1, 3, 2, 1, 7])\n",
    "\n",
    "# Menggunakan np.bincount() untuk menghitung frekuensi\n",
    "bincount_result = np.bincount(arr)\n",
    "\n",
    "print(bincount_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
